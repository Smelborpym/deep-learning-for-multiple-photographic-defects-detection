{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "with open('../paths.json', 'r') as f:\n",
    "    paths = json.load(f)\n",
    "    pdownloads = paths[\"paths\"][paths[\"cloud\"]][\"downloads\"]\n",
    "    pdatasets = paths[\"paths\"][paths[\"cloud\"]][\"datasets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not(os.path.isdir(pdownloads))):\n",
    "    !mkdir $pdownloads\n",
    "if(not(os.path.isdir(pdatasets))):\n",
    "    !mkdir $pdatasets\n",
    "    !mkdir $pdatasets/ava\n",
    "    !mkdir $pdatasets/ava/labels\n",
    "    !mkdir $pdatasets/ava/images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download AVA dataset via rtorrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://academictorrents.com/download/71631f83b11d3d79d8f84efe0a7e12f0ac001460.torrent -P $pdownloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command directly in a bash session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd $pdownloads ; sudo rtorrent 71631f83b11d3d79d8f84efe0a7e12f0ac001460.torrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $pdownloads/AVA_dataset/README.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command directly in a bash session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd $pdatasets/ava/images ; sudo 7z e $pdownloads/AVA_dataset/images/images.7z.001 -aos > ../7z.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps -aux | grep 7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../datasets/ava/7z.log | tail -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../datasets/ava/images | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing images & download them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "with open('ava labels/ava_labels_test.json', 'r') as f:\n",
    "    test_json = json.load(f)\n",
    "with open(pdownloads+'/ava_labels_train.json', 'r') as f:\n",
    "    train_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for iid in test_json['image_id']:\n",
    "    name = test_json['image_id'][iid]\n",
    "    file = name[0: -4]\n",
    "    if(not(os.path.isfile(pdatasets+'/ava/images/' + name))):\n",
    "        !wget https:$(wget -O - https://www.dpchallenge.com/image.php?IMAGE_ID=$file | grep -o \"//images\\.dpchallenge\\.com/images_challenge/[0-9]*-[0-9]*/[0-9]*/[0-9]*/Copyrighted_Image_Reuse_Prohibited_$name\")\n",
    "        !mv Copyrighted_Image_Reuse_Prohibited_$name $pdatasets/ava/images/$name\n",
    "        i = i + 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for iid in train_json['image_id']:\n",
    "    name = train_json['image_id'][iid]\n",
    "    file = name[0: -4]\n",
    "    if(not(os.path.isfile(pdatasets+'/ava/images/' + name))):\n",
    "        !wget https:$(wget -O - https://www.dpchallenge.com/image.php?IMAGE_ID=$file | grep -o \"//images\\.dpchallenge\\.com/images_challenge/[0-9]*-[0-9]*/[0-9]*/[0-9]*/Copyrighted_Image_Reuse_Prohibited_$name\")\n",
    "        !mv Copyrighted_Image_Reuse_Prohibited_$name $pdatasets/ava/images/$name\n",
    "        i = i + 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for 0 sized files, to re-download them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find $pdatasets/ava/images -size 0 -print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually remove them and re-download them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '220902'\n",
    "name = file + '.jpg'\n",
    "!rm $pdatasets/ava/images/$name\n",
    "!wget https:$(wget -O - https://www.dpchallenge.com/image.php?IMAGE_ID=$file | grep -o \"//images\\.dpchallenge\\.com/images_challenge/[0-9]*-[0-9]*/[0-9]*/[0-9]*/Copyrighted_Image_Reuse_Prohibited_$name\")\n",
    "!mv Copyrighted_Image_Reuse_Prohibited_$name $pdatasets/ava/images/$name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for files that cannot be opened by PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_json('ava labels/train.json')\n",
    "test_df = pd.read_json('ava labels/test.json')\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "failed = []\n",
    "i = 0\n",
    "f = 0\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "for x in df[\"image_id\"]:\n",
    "    i = i + 1\n",
    "    try:\n",
    "        img = Image.open(pdatasets+'/ava/images/' + x, 'r')\n",
    "    except:\n",
    "        failed.append(x)\n",
    "        f = f + 1\n",
    "    print(\"processed \" + str(i) + \", failed \" + str(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
